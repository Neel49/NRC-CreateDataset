{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "Copyright (c) 2021, Her Majesty in Right of Canada as represented by the National Research Council Canada. Rights provided under GNU GENERAL PUBLIC LICENSE, Version 3. Full text of the license accessible at the [LICENSE](LICENSE) file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scripts automatically collect videos from the following sources, processes and curates them, and stores them along with their metadata on the user's device:\n",
    "\n",
    "* ButterflyNetwork\n",
    "* GrepMed\n",
    "* LITFL\n",
    "* The PocusAtlas\n",
    "* Radiopaedia\n",
    "* CoreUltrasound\n",
    "* University of Florida (UF)\n",
    "* Scientific Publications\n",
    "* Clarius\n",
    "\n",
    "In addition, it extracts images from the collected videos, processes and curates them, and stores images and their metadata locally on the user's device.\n",
    "\n",
    "__Note:__ No data is stored on the NRC-COVIDx-US repository and it only contains scripts to systematically collect, curate, and integrate data on user's device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random \n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "from vimeo_downloader import Vimeo\n",
    "import urllib.request\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import time\n",
    "from image_data import extract_images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas 2.1.4\n",
      "selenium 4.15.2\n",
      "requests 2.31.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas\", pd.__version__)\n",
    "import selenium\n",
    "print(\"selenium\", selenium.__version__)\n",
    "print(\"requests\", requests.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_path():\n",
    "    \"\"\"Returns the default downloads path for linux or windows\"\"\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            location = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "        return location\n",
    "    else:\n",
    "        return os.path.join(os.path.expanduser('~'), 'downloads')\n",
    "    \n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Function to remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set save path directory\n",
    "SAVE_PATH = 'data'\n",
    "\n",
    "# create data, video, and image folders, if they do not exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('data/video'):\n",
    "    os.makedirs('data/video')\n",
    "if not os.path.exists('data/image'):\n",
    "    os.makedirs('data/image')\n",
    "    \n",
    "# setting chrome driver\n",
    "chromedriver = \"utils/chromedriver.exe\" \n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# setting global vars\n",
    "VIDEO_PATH = 'data/video/'\n",
    "IMAGE_PATH = 'data/image/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filetype</th>\n",
       "      <th>folder</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>probe</th>\n",
       "      <th>class</th>\n",
       "      <th>class_on_website</th>\n",
       "      <th>version</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>patient</th>\n",
       "      <th>case_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>comment</th>\n",
       "      <th>paper_link</th>\n",
       "      <th>paper_doi</th>\n",
       "      <th>license</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_butterfly_covid</td>\n",
       "      <td>Coalescing B lines.mp4</td>\n",
       "      <td>mp4</td>\n",
       "      <td>data\\tmp\\Butterfly\\B lines</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>https://butterflynetwork.getbynder.com/transfe...</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>lung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_butterfly_covid</td>\n",
       "      <td>Confluent B lines.mp4</td>\n",
       "      <td>mp4</td>\n",
       "      <td>data\\tmp\\Butterfly\\B lines</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>https://butterflynetwork.getbynder.com/transfe...</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>lung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                filename filetype  \\\n",
       "0  1_butterfly_covid  Coalescing B lines.mp4      mp4   \n",
       "1  2_butterfly_covid   Confluent B lines.mp4      mp4   \n",
       "\n",
       "                       folder     source  \\\n",
       "0  data\\tmp\\Butterfly\\B lines  Butterfly   \n",
       "1  data\\tmp\\Butterfly\\B lines  Butterfly   \n",
       "\n",
       "                                                 url   probe  class  \\\n",
       "0  https://butterflynetwork.getbynder.com/transfe...  Convex  COVID   \n",
       "1  https://butterflynetwork.getbynder.com/transfe...  Convex  COVID   \n",
       "\n",
       "  class_on_website  version  ...  type patient case_no  gender age  comment  \\\n",
       "0              NaN      1.0  ...  lung     NaN     NaN     NaN NaN      NaN   \n",
       "1              NaN      1.0  ...  lung     NaN     NaN     NaN NaN      NaN   \n",
       "\n",
       "  paper_link paper_doi license link  \n",
       "0        NaN       NaN     NaN  NaN  \n",
       "1        NaN       NaN     NaN  NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('utils/video_metadata.csv', sep=',', encoding='latin1')\n",
    "print(metadata.shape)\n",
    "metadata.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Ultrasound Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ButterflyNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note1:__ Depending on your system configuration the download button may not load in time. If you get an error, increase the sleep time in the following code:\n",
    "\n",
    "```python\n",
    "time.sleep(5)\n",
    "```\n",
    "\n",
    "To get the videos mentioned in this script, please follow these steps:\n",
    "\n",
    "\n",
    "* Visit the Google Drive link: \"https://drive.google.com/drive/folders/1pN6Gk_bjGIlsM5mSj_TDjIn-_4sY5r0G?usp=sharing\n",
    "* Download the entire folder to your computer.\n",
    "* It will download as a zip folder. \n",
    "* Extract all the .mp4 file from the folder.\n",
    "* Move the .mp4 files into the video folder that is inside the data folder within the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. GrepMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% (12 of 20) |##############          | Elapsed Time: 0:00:03 ETA:   0:00:02"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m row\u001b[38;5;241m.\u001b[39mfiletype\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# write the video file to disk\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m vid \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/video/\u001b[39m\u001b[38;5;124m'\u001b[39m, filename), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handler:\n\u001b[0;32m     10\u001b[0m     handler\u001b[38;5;241m.\u001b[39mwrite(vid)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[0;32m   1099\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1100\u001b[0m         (\n\u001b[0;32m   1101\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconn\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1107\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_time_off:\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39mis_verified\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:782\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    780\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 782\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:470\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# Defensive: in CI, we always have set_alpn_protocols\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:514\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    511\u001b[0m     SSLTransport\u001b[38;5;241m.\u001b[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1069\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "grepmed_df = metadata[metadata.source == 'GrepMed']\n",
    "\n",
    "progress = ProgressBar(max_value=grepmed_df.shape[0]) \n",
    "for idx, row in progress(grepmed_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    # write the video file to disk\n",
    "    vid = requests.get(row.url).content\n",
    "    with open(os.path.join('data/video/', filename), 'wb') as handler:\n",
    "        handler.write(vid)\n",
    "print('=== GrepMed video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. LITFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 63) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (63 of 63) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LITFL video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "litfl_df = metadata[metadata.source == 'Litfl']\n",
    "\n",
    "progress = ProgressBar(max_value=litfl_df.shape[0]) \n",
    "for idx, row in progress(litfl_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    # write the video file to disk\n",
    "    vid = requests.get(row.url).content\n",
    "    with open(os.path.join('data/video/', filename), 'wb') as handler:\n",
    "        handler.write(vid)\n",
    "print('=== LITFL video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. The POCUS Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 32) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (32 of 32) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== THEPocusAtlas video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "pocus_df = metadata[metadata.source == 'PocusAtlas']\n",
    "\n",
    "progress = ProgressBar(max_value=pocus_df.shape[0]) \n",
    "for idx, row in progress(pocus_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    # write the video file to disk\n",
    "    vid = requests.get(row.url).content\n",
    "    with open(os.path.join('data/video/', filename), 'wb') as handler:\n",
    "        handler.write(vid)\n",
    "print('=== THEPocusAtlas video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Radiopaedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% (1 of 5) |#####                     | Elapsed Time: 0:00:00 ETA:   0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Radiopaedia video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "radio_df = metadata[metadata.source == 'Radiopaedia']\n",
    "\n",
    "progress = ProgressBar(max_value=radio_df.shape[0]) \n",
    "for idx, row in progress(radio_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    # write the video file to disk\n",
    "    vid = requests.get(row.url).content\n",
    "    with open(os.path.join('data/video/', filename), 'wb') as handler:\n",
    "        handler.write(vid)\n",
    "print('=== Radiopaedia video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. CoreUltrasound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 18) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157_core_other.mp4: 1294KB [00:00, 9961.66KB/s]                                                                                                                               \n",
      "158_core_pneumonia.mp4: 3892KB [00:00, 11616.21KB/s]                                                                                                                          \n",
      "159_core_other.mp4: 3847KB [00:00, 11100.06KB/s]                                                                                                                              \n",
      "160_core_other.mp4: 3847KB [00:00, 10417.26KB/s]                                                                                                                              \n",
      "161_core_other.mp4: 4805KB [00:00, 11089.26KB/s]                                                                                                                              \n",
      "162_core_other.mp4: 4805KB [00:00, 11085.45KB/s]                                                                                                                              \n",
      "174_core_covid.mp4: 1633KB [00:00, 11967.77KB/s]                                                                                                                              \n",
      "100% (18 of 18) |########################| Elapsed Time: 0:00:13 Time:  0:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoreUltrasound video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "core_df = metadata[metadata.source == 'CoreUltrasound']\n",
    "\n",
    "progress = ProgressBar(max_value=core_df.shape[0]) \n",
    "for idx, row in progress(core_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    \n",
    "    # extract videos from Vimeo\n",
    "    if 'vimeo' in row.url:\n",
    "        v = Vimeo(row.url)\n",
    "        stream = v.streams # List of available streams of different quality\n",
    "        highest_quality_available = stream[-1]\n",
    "        highest_quality_available.download(download_directory = 'data/video/', filename = filename.split('.')[0])\n",
    "    # extract mp4 videos\n",
    "    else:\n",
    "        # write the video file to disk\n",
    "        vid = requests.get(row.url).content\n",
    "        with open(os.path.join('data/video/', filename), 'wb') as handler:\n",
    "            handler.write(vid)\n",
    "print('=== CoreUltrasound video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2 of 2) |##########################| Elapsed Time: 0:00:09 Time:  0:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2 extra video files downloaded! ===\n"
     ]
    }
   ],
   "source": [
    "paper_df = metadata[(metadata.source == 'Paper') & ((metadata['id'].str.contains('199', na=False)) | (metadata['id'].str.contains('200', na=False)))] \n",
    "\n",
    "progress = ProgressBar(max_value=paper_df.shape[0]) \n",
    "for idx, row in progress(paper_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    \n",
    "    # write the video file to disk\n",
    "    r = requests.get(row.url, stream=True, headers={'User-agent': 'Mozilla/5.0'})\n",
    "    if r.status_code == 200:\n",
    "        with open(os.path.join('data/video/', filename), 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)       \n",
    "\n",
    "    # set a random delay, otherwise the connection gets closed\n",
    "    delay = random.randint(3, 5)\n",
    "    time.sleep(delay)\n",
    "print('=== 2 extra video files downloaded! ===')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 24) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (24 of 24) |########################| Elapsed Time: 0:02:19 Time:  0:02:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UF video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "uf_df = metadata[metadata.source == 'UF']\n",
    "\n",
    "progress = ProgressBar(max_value=uf_df.shape[0]) \n",
    "for idx, row in progress(uf_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    \n",
    "    # write the video file to disk\n",
    "    r = requests.get(row.url, stream=True, headers={'User-agent': 'Mozilla/5.0'})\n",
    "    if r.status_code == 200:\n",
    "        with open(os.path.join('data/video/', filename), 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)       \n",
    "\n",
    "    # set a random delay, otherwise the connection gets closed\n",
    "    delay = random.randint(3, 5)\n",
    "    time.sleep(delay)\n",
    "print('=== UF video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Scientific Publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 22) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22 of 22) |########################| Elapsed Time: 0:02:21 Time:  0:02:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Video files extraction from papers is done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "paper_df = metadata[(metadata.source == 'Paper')] \n",
    "\n",
    "progress = ProgressBar(max_value=paper_df.shape[0]) \n",
    "for idx, row in progress(paper_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    \n",
    "    r = requests.get(row.url, stream=True, headers={'User-agent': 'Mozilla/5.0'})\n",
    "    if r.status_code == 200:\n",
    "        with open(os.path.join('data/video/', filename), 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)       \n",
    "        \n",
    "    # set a random delay, otherwise the connection gets closed\n",
    "    if (('241_' in row.id) | ('242_' in row.id) | ('243_' in row.id)): #longer delay for last files\n",
    "        delay = random.randint(10, 20)\n",
    "    else:\n",
    "        delay = random.randint(3, 5)\n",
    "    time.sleep(delay)\n",
    "print('=== Video files extraction from papers is done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Clarius\n",
    "* Extracting the first part of Clarius files (**6 files**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 6) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Extracting the video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (6 of 6) |##########################| Elapsed Time: 0:00:24 Time:  0:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Clarius video files extraction done! ===\n"
     ]
    }
   ],
   "source": [
    "print('...Extracting the video files...')\n",
    "clarius_df = metadata[metadata.source == 'Clarius'].iloc[:6, :]\n",
    "\n",
    "progress = ProgressBar(max_value=clarius_df.shape[0]) \n",
    "for idx, row in progress(clarius_df.iterrows()):\n",
    "    filename = row.id + '.' + row.filetype\n",
    "    \n",
    "    # write the video file to disk\n",
    "    r = requests.get(row.url, stream=True, headers={'User-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64)'})\n",
    "    if r.status_code == 200:\n",
    "        with open(os.path.join('data/video/', filename), 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)       \n",
    "\n",
    "    # set a random delay, otherwise the connection gets closed\n",
    "    delay = random.randint(3, 5)\n",
    "    time.sleep(delay)\n",
    "print('=== Clarius video files extraction done! ===')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extracting the second part of Clarius files (**17 files**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Video Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move original video files to the original folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 2) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path 'data/video/original\\cropped' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m progress \u001b[38;5;241m=\u001b[39m ProgressBar()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m progress(file_names):\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:813\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    810\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> 813\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path 'data/video/original\\cropped' already exists"
     ]
    }
   ],
   "source": [
    "source_dir = 'data/video/'\n",
    "target_dir = 'data/video/original'\n",
    "    \n",
    "file_names = os.listdir(source_dir)\n",
    "\n",
    "if not os.path.exists('data/video/original'): \n",
    "    os.makedirs('data/video/original') \n",
    "\n",
    "progress = ProgressBar()\n",
    "for file_name in progress(file_names):\n",
    "    shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Fetching Video Files Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (244 of 244) |######################| Elapsed Time: 0:00:02 Time:  0:00:02\n"
     ]
    }
   ],
   "source": [
    "VIDEO_PATH_ORG = 'data/video/original/'\n",
    "\n",
    "vid_files = os.listdir(VIDEO_PATH_ORG)\n",
    "\n",
    "progress = ProgressBar(max_value=metadata.shape[0]) \n",
    "with open('utils/video_files_properties.csv', 'w') as f:\n",
    "    # write the file header\n",
    "    f.write('filename,framerate,width,height,frame_count,duration_secs\\n')\n",
    "    \n",
    "    # loop over the video files and get their properties\n",
    "    for vid in progress(vid_files):\n",
    "        vid_filename = VIDEO_PATH_ORG + str(vid)\n",
    "        file_type = vid.split('.')[-1]\n",
    "        \n",
    "        # get video file properties\n",
    "        cv2video = cv2.VideoCapture(vid_filename)\n",
    "        height = cv2video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        width  = cv2video.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "        frame_rate = round(cv2video.get(cv2.CAP_PROP_FPS), 2)\n",
    "        \n",
    "        if file_type == 'mp4':\n",
    "            frame_count = cv2video.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "            duration = round((frame_count / frame_rate), 2)\n",
    "        elif file_type == 'gif':\n",
    "            frame_count = round(Image.open(vid_filename).n_frames) #round((duration * frame_rate ), 0)\n",
    "            duration = round((frame_count / frame_rate), 2)\n",
    "\n",
    "        # write video properties to the file\n",
    "        line_to_write = str(vid) + ',' + str(frame_rate) + ',' + str(width) + ',' + str(height) + ',' + str(frame_count) + ',' + str(duration) + '\\n'\n",
    "        f.write(line_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Video Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "VIDEO_CROPPED_OUT = 'data/video/cropped/' #processed/cropped/'\n",
    "\n",
    "# create processed and cropped folder if they don't already exist\n",
    "if not os.path.exists('data/video/cropped'): #processed/cropped'):\n",
    "    os.makedirs('data/video/cropped') #processed/cropped')\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Inital Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>source</th>\n",
       "      <th>probe</th>\n",
       "      <th>class</th>\n",
       "      <th>org_width</th>\n",
       "      <th>org_height</th>\n",
       "      <th>org_framecount</th>\n",
       "      <th>org_framerate</th>\n",
       "      <th>org_duration</th>\n",
       "      <th>green_dot</th>\n",
       "      <th>...</th>\n",
       "      <th>del_upper</th>\n",
       "      <th>width_rate</th>\n",
       "      <th>x1_w_y1_h</th>\n",
       "      <th>cropped_filename</th>\n",
       "      <th>crp_width</th>\n",
       "      <th>crp_height</th>\n",
       "      <th>version</th>\n",
       "      <th>date_added</th>\n",
       "      <th>multiple_videos</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_butterfly_covid.mp4</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>880</td>\n",
       "      <td>1080</td>\n",
       "      <td>65</td>\n",
       "      <td>19.57</td>\n",
       "      <td>3.32</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_butterfly_covid_prc.avi</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nov_2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_butterfly_covid.mp4</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>720</td>\n",
       "      <td>1236</td>\n",
       "      <td>818</td>\n",
       "      <td>30.00</td>\n",
       "      <td>27.27</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_butterfly_covid_prc.avi</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nov_2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename     source   probe  class  org_width  org_height  \\\n",
       "0  1_butterfly_covid.mp4  Butterfly  Convex  COVID        880        1080   \n",
       "1  2_butterfly_covid.mp4  Butterfly  Convex  COVID        720        1236   \n",
       "\n",
       "   org_framecount  org_framerate  org_duration green_dot  ... del_upper  \\\n",
       "0              65          19.57          3.32        no  ...      15.0   \n",
       "1             818          30.00         27.27       yes  ...      83.0   \n",
       "\n",
       "  width_rate x1_w_y1_h           cropped_filename crp_width crp_height  \\\n",
       "0      0.035       NaN  1_butterfly_covid_prc.avi       820        820   \n",
       "1      0.068       NaN  2_butterfly_covid_prc.avi       624        624   \n",
       "\n",
       "  version  date_added  multiple_videos Note  \n",
       "0     1.0    Nov_2020              NaN  NaN  \n",
       "1     1.0    Nov_2020              NaN  NaN  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read cropping metadata file\n",
    "vid_crp_metadata = pd.read_csv('utils/video_cropping_metadata.csv', sep=',', encoding='latin1')\n",
    "print(vid_crp_metadata.shape)\n",
    "vid_crp_metadata.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vid_arr = np.asarray(vid_arr)\n",
    "if vid_arr.size > 0:\n",
    "    prc_dim = vid_arr.shape[1:3]  # dimension of the cropped file\n",
    "    if len(prc_dim) == 2:  # Ensure prc_dim has two elements\n",
    "        prc_dim = (prc_dim[1], prc_dim[0])\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(os.path.join(VIDEO_CROPPED_OUT, filename.split('.')[0] + '_prc.avi'), fourcc, 20.0, prc_dim)\n",
    "\n",
    "        for frame in vid_arr:\n",
    "            out.write(frame.astype(\"uint8\"))\n",
    "\n",
    "        vid_crp_metadata.iloc[idx, vid_crp_metadata.columns.get_loc('crp_width')] = prc_dim[1]\n",
    "        vid_crp_metadata.iloc[idx, vid_crp_metadata.columns.get_loc('crp_height')] = prc_dim[0]\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(f\"No frames captured for video: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (241 of 241) |######################| Elapsed Time: 0:02:29 Time:  0:02:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cropping done...\n"
     ]
    }
   ],
   "source": [
    "progress = ProgressBar(max_value=vid_crp_metadata.shape[0])\n",
    "\n",
    "for idx, row in progress(vid_crp_metadata.iterrows()):\n",
    "    vid_arr = []  # array to store frames of a video file\n",
    "    \n",
    "    filename = row.filename\n",
    "    file_label = filename.split('_')[-1].split('.')[0] # label of the video file\n",
    "    \n",
    "    # the following file was removed in the new release of butterfly data\n",
    "    if filename == '22_butterfly_covid.mp4':\n",
    "        continue\n",
    "    \n",
    "    cap = cv2.VideoCapture(os.path.join(VIDEO_PATH_ORG, filename))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "    dim = (width, height) # dimension of the original file\n",
    "    \n",
    "    if pd.isna(row.x1_w_y1_h): # square cropping\n",
    "        DEL_UPPER = int(row.del_upper) # to remove top\n",
    "        WIDTH_RATE = float(row.width_rate) # to remove sides e.g. the meter\n",
    "        \n",
    "        width_border = int(width * WIDTH_RATE)\n",
    "        width_box = int(width - (2 * width_border)) \n",
    "        if width_box + DEL_UPPER > height:\n",
    "            width_box = int(height - DEL_UPPER)\n",
    "            width_border = int( (width / 2) - (width_box / 2))\n",
    "\n",
    "        while(True):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # crop\n",
    "            frame = frame[DEL_UPPER:width_box + DEL_UPPER, width_border:width_box + width_border]\n",
    "\n",
    "            frame = np.asarray(frame).astype(np.uint8)\n",
    "            vid_arr.append(frame)\n",
    "\n",
    "    else: # crop using (x1,y1) and (x2, y2). The output will not be necessarily a square file\n",
    "        X1 = int(row.x1_w_y1_h.split(',')[0].replace('(', ''))\n",
    "        W = int(row.x1_w_y1_h.split(',')[1].strip())\n",
    "        Y1 = int(row.x1_w_y1_h.split(',')[2].strip())\n",
    "        H = int(row.x1_w_y1_h.split(',')[3].replace(')', '').strip())\n",
    "\n",
    "        while(True):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # crop\n",
    "            frame = frame[Y1:Y1 + H, X1:X1 + W]\n",
    "\n",
    "            frame = np.asarray(frame).astype(np.uint8)\n",
    "            vid_arr.append(frame)\n",
    "\n",
    "    vid_arr = np.asarray(vid_arr)\n",
    "    prc_dim = vid_arr.shape[1:3] # dimension of the cropped file\n",
    "    prc_dim = (prc_dim[1], prc_dim[0])\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(os.path.join(VIDEO_CROPPED_OUT + filename.split('.')[0] + '_prc.avi'), fourcc, 20.0, tuple(prc_dim))\n",
    "\n",
    "    for frame in vid_arr:\n",
    "        out.write(frame.astype(\"uint8\"))\n",
    "\n",
    "    vid_crp_metadata.iloc[idx, vid_crp_metadata.columns.get_loc('crp_width')] = prc_dim[1]\n",
    "    vid_crp_metadata.iloc[idx, vid_crp_metadata.columns.get_loc('crp_height')] = prc_dim[0]\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "vid_crp_metadata.to_csv('utils/video_cropping_metadata.csv', index=None)\n",
    "\n",
    "print('Initial cropping done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract Ultrasound Images from Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read video properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>framerate</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>duration_secs</th>\n",
       "      <th>source</th>\n",
       "      <th>probe</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_litfl_other.mp4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>Litfl</td>\n",
       "      <td>Convex</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101_litfl_other.mp4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.87</td>\n",
       "      <td>Litfl</td>\n",
       "      <td>Convex</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  framerate  width  height  frame_count  duration_secs  \\\n",
       "0  100_litfl_other.mp4       15.0  480.0   360.0         46.0           3.07   \n",
       "1  101_litfl_other.mp4       15.0  480.0   360.0         28.0           1.87   \n",
       "\n",
       "  source   probe  class  \n",
       "0  Litfl  Convex  Other  \n",
       "1  Litfl  Convex  Other  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_prop_df = pd.read_csv('utils/video_files_properties.csv')\n",
    "\n",
    "# merge with the video meta data file \n",
    "vid_prop_df.filename = vid_prop_df.filename.astype(str)\n",
    "vid_prop_df.filename = vid_prop_df.filename.str.strip()\n",
    "\n",
    "metadata['filename2'] = metadata.id + '.' + metadata.filetype\n",
    "metadata.filename2 = metadata.filename2.astype(str)\n",
    "metadata.filename2 = metadata.filename2.str.strip()\n",
    "\n",
    "vid_prop_df = pd.merge(vid_prop_df, metadata[['filename2', 'source', 'probe', 'class']], left_on='filename', right_on='filename2', how='left').drop('filename2', axis=1)\n",
    "\n",
    "del metadata['filename2']\n",
    "print(vid_prop_df.shape)\n",
    "vid_prop_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract frames from original videos\n",
    "* v1.4.: 32,052 images are extracted\n",
    "* v1.3.: 19,161 images are extracted\n",
    "* v1.2.: 15,282 images are extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH_ORG = 'data/image/original/'\n",
    "\n",
    "# create a folder for images extracted from original videos, if doesn't exist\n",
    "if not os.path.exists(IMAGE_PATH_ORG):\n",
    "    os.makedirs(IMAGE_PATH_ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (240 of 241) |##################### | Elapsed Time: 0:04:06 ETA:   0:00:02"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVIDEO_PATH_ORG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMAGE_PATH_ORG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\COVID-US\\image_data.py:57\u001b[0m, in \u001b[0;36mextract_images\u001b[1;34m(video_path, image_path, cropped, max_frames, target_class, target_source, target_probe)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m#frame_rate = row.framerate\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     frame_count \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mframe_count\n\u001b[1;32m---> 57\u001b[0m vid_probe \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# read the video file and extracting frames\u001b[39;00m\n\u001b[0;32m     60\u001b[0m cv2video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(filename))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "extract_images(video_path= VIDEO_PATH_ORG, image_path=IMAGE_PATH_ORG, cropped=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Extract frames from cropped video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CROPPED_OUT = 'data/image/cropped/'\n",
    "IMAGE_MASK_OUT = 'data/mask/'\n",
    "\n",
    "# create cropped and inpainted image folders and the mask folder if they don't already exist\n",
    "if not os.path.exists(IMAGE_CROPPED_OUT):\n",
    "    os.makedirs(IMAGE_CROPPED_OUT)\n",
    "if not os.path.exists(IMAGE_MASK_OUT):\n",
    "    os.makedirs(IMAGE_MASK_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (241 of 241) |######################| Elapsed Time: 0:03:42 Time:  0:03:42\n"
     ]
    }
   ],
   "source": [
    "extract_images(video_path= VIDEO_CROPPED_OUT, image_path=IMAGE_CROPPED_OUT, cropped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. (Optional) Extracting frames from cropped ultrasouund video files using a parameter set as filter\n",
    "* You can extract images using the follwoing parameters:\n",
    "    * maximum number of frames to be extracted from each video file\n",
    "    * extracting a targetted set of classes from ['COVID', 'Pneumonia', 'Normal', 'Other']\n",
    "    * extracting a targetted set of data sources from ['Butterfly', 'GrepMed', 'LITFL', 'PocusAtlas', 'CU', 'Radiopaedia', 'UF', 'Paper', 'Clarius']\n",
    "    * extracting a targetted set of probes from ['convex', 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_images(video_path= VIDEO_CROPPED_OUT, image_path=IMAGE_CROPPED_OUT, cropped=True, \n",
    "#                max_frames=10, \n",
    "#                target_class=['COVID', 'Pneumonia', 'Normal'],\n",
    "#                target_source=['Butterfly', 'GrepMed', 'LITFL', 'PocusAtlas'],\n",
    "#                target_probe=['convex', 'linear']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read image preprocessing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>source</th>\n",
       "      <th>probe</th>\n",
       "      <th>class</th>\n",
       "      <th>org_width</th>\n",
       "      <th>org_height</th>\n",
       "      <th>cropped_filename</th>\n",
       "      <th>crp_width</th>\n",
       "      <th>crp_height</th>\n",
       "      <th>need_mask_after_crop</th>\n",
       "      <th>need_multiple_masks</th>\n",
       "      <th>frame_specific_masks</th>\n",
       "      <th>delete_frames_from_to</th>\n",
       "      <th>mask_main_filename</th>\n",
       "      <th>tight_inpainting</th>\n",
       "      <th>version</th>\n",
       "      <th>date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_butterfly_covid.mp4</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>880</td>\n",
       "      <td>1080</td>\n",
       "      <td>1_butterfly_covid_prc.avi</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_butterfly_covid_prc_convex_frame0_mask.jpg</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nov_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_butterfly_covid.mp4</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>Convex</td>\n",
       "      <td>COVID</td>\n",
       "      <td>720</td>\n",
       "      <td>1236</td>\n",
       "      <td>2_butterfly_covid_prc.avi</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>118-130, 134-139, 147-150</td>\n",
       "      <td>131-133, 143-146, 154-202, 210-813</td>\n",
       "      <td>2_butterfly_covid_prc_convex_frame0_mask.jpg</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nov_2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename     source   probe  class  org_width  org_height  \\\n",
       "0  1_butterfly_covid.mp4  Butterfly  Convex  COVID        880        1080   \n",
       "1  2_butterfly_covid.mp4  Butterfly  Convex  COVID        720        1236   \n",
       "\n",
       "            cropped_filename  crp_width  crp_height need_mask_after_crop  \\\n",
       "0  1_butterfly_covid_prc.avi        820         820                  yes   \n",
       "1  2_butterfly_covid_prc.avi        624         624                  yes   \n",
       "\n",
       "  need_multiple_masks       frame_specific_masks  \\\n",
       "0                  no                        NaN   \n",
       "1                 yes  118-130, 134-139, 147-150   \n",
       "\n",
       "                delete_frames_from_to  \\\n",
       "0                                 NaN   \n",
       "1  131-133, 143-146, 154-202, 210-813   \n",
       "\n",
       "                             mask_main_filename tight_inpainting  version  \\\n",
       "0  1_butterfly_covid_prc_convex_frame0_mask.jpg               no      1.0   \n",
       "1  2_butterfly_covid_prc_convex_frame0_mask.jpg               no      1.0   \n",
       "\n",
       "  date_added  \n",
       "0   Nov_2020  \n",
       "1   Nov_2020  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_prc_df = pd.read_csv('utils/mask_metadata.csv')\n",
    "\n",
    "image_prc_df = image_prc_df[image_prc_df.filename !='22_butterfly_covid.mp4'] # 22_butterfly_covid.mp4 was removed in March release of butterfly\n",
    "\n",
    "print(image_prc_df.shape)\n",
    "image_prc_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Removing frames with artifacts on the ROI\n",
    "Some frames of the following files need to be deleted as the moving pointer is on ROI, we will remove them from the cropped images folder:\n",
    "* 2_butterfly_covid.mp4\n",
    "* 6_butterfly_covid.mp4\n",
    "* 16_butterfly_covid.mp4\n",
    "* 20_butterfly_normal.mp4\n",
    "* 22_butterfly_covid.mp4 (it was removed in the March release of butterfly data)\n",
    "* 25_grepmed_pneumonia.mp4\n",
    "* 178_uf_other.mp4 (initial 30 frames are removed)\n",
    "* 184_uf_pneumonia.mp4 (initial 30 frames are removed)\n",
    "\n",
    "We need 2 masks for the following videos:\n",
    "* 178_uf_other.mp4 \n",
    "* 184_uf_pneumonia.mp4\n",
    "\n",
    "**Number of frames:**\n",
    "* __Initial total number of frames:__ \n",
    "    * v1.4.: 32,052\n",
    "    * v1.3.: 19,161\n",
    "    * v1.2.: 13,646\n",
    "* __Total number of frames after removal:__ \n",
    "    * v1.4.: 29,651\n",
    "    * v1.3.: 16,822\n",
    "    * v1.2.: 11,307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 7) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'data/image/cropped/2_butterfly_covid_prc_convex_frame131.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(from_frame, to_frame):\n\u001b[0;32m     13\u001b[0m             file_to_remove \u001b[38;5;241m=\u001b[39m IMAGE_CROPPED_OUT \u001b[38;5;241m+\u001b[39m frame_name_main \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_frame\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m             \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_to_remove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Files removed! ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'data/image/cropped/2_butterfly_covid_prc_convex_frame131.jpg'"
     ]
    }
   ],
   "source": [
    "progress = ProgressBar(max_value=image_prc_df[~pd.isna(image_prc_df.delete_frames_from_to)].shape[0])\n",
    "\n",
    "for idx, row in progress(image_prc_df[~pd.isna(image_prc_df.delete_frames_from_to)].iterrows()):\n",
    "    frames_to_delete = row.delete_frames_from_to.strip().split(',')\n",
    "    frame_name_main = row.mask_main_filename.split('.')[0].split('_frame')[0]\n",
    "    \n",
    "    for frames in frames_to_delete:\n",
    "        from_frame = int(frames.split('-')[0])\n",
    "        to_frame = int(frames.split('-')[1]) + 1\n",
    "        \n",
    "        # delete frames with moving part on the roi\n",
    "        for i in range(from_frame, to_frame):\n",
    "            file_to_remove = IMAGE_CROPPED_OUT + frame_name_main + '_frame' + str(i) + '.jpg'\n",
    "            os.remove(file_to_remove)\n",
    "\n",
    "print(\"=== Files removed! ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Applying masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_IMAGE_OUT = 'data/image/clean/'\n",
    "CLEAN_VIDEO_OUT = 'data/video/clean/'\n",
    "\n",
    "# create clean image and video folders if they don't already exist\n",
    "if not os.path.exists(CLEAN_IMAGE_OUT):\n",
    "    os.makedirs(CLEAN_IMAGE_OUT)\n",
    "if not os.path.exists(CLEAN_VIDEO_OUT):\n",
    "    os.makedirs(CLEAN_VIDEO_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad_array(arr, pad=5):\n",
    "    if len(arr.shape) == 3:\n",
    "        padded_arr = np.zeros((arr.shape[0]+2*pad, arr.shape[1]+2*pad, arr.shape[2]), dtype=np.uint8)\n",
    "        padded_arr[pad:pad + arr.shape[0], pad:pad + arr.shape[1], :] = arr\n",
    "    else:\n",
    "        padded_arr = np.zeros((arr.shape[0]+2*pad, arr.shape[1]+2*pad), dtype=np.uint8)\n",
    "        padded_arr[pad:pad + arr.shape[0], pad:pad + arr.shape[1]] = arr\n",
    "    return padded_arr\n",
    "        \n",
    "\n",
    "def frame_inpainting(frame_dict, mask, default_mask=0, kernel_size=(5,5), method='telea', pad=5):\n",
    "    '''\n",
    "    The function performs inpainting on frames using the created masks\n",
    "    \n",
    "    - frame_dict: dict of frames from video, indexed by frame number\n",
    "    - mask: (h, w, 1) array if single mask, else dict of such arrays\n",
    "        indexed by frame number\n",
    "    - default_mask: index for mask to be used as default, for frames\n",
    "        without specific mask (if mask is not constant across frames)\n",
    "    - kernel_size: Size of patch used to perform inpainting\n",
    "    - method: one of 'ns' (navier-stokes) or 'telea' - telea usually works better\n",
    "    '''\n",
    "    # Dilate mask make sure it covers enough of the ROI to be masked\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    if type(mask) is not dict:\n",
    "        mask = {default_mask: mask}\n",
    "    masks_processed = {key:cv2.dilate(zero_pad_array(m, pad=pad), kernel, iterations=1) for key, m in mask.items()}\n",
    "    \n",
    "    method_dict = {'ns':cv2.INPAINT_NS, 'telea':cv2.INPAINT_TELEA}\n",
    "    \n",
    "    frames_inpainted = {}\n",
    "    for key, frame in frame_dict.items():\n",
    "        if key in masks_processed:\n",
    "            #print(frame.shape, masks_processed[key].shape)\n",
    "            frames_inpainted[key] = cv2.inpaint(zero_pad_array(frame, pad=pad), masks_processed[key], 3, method_dict[method])[pad:-pad, pad:-pad, :]\n",
    "        else: # default mask\n",
    "            frames_inpainted[key] = cv2.inpaint(zero_pad_array(frame, pad=pad), masks_processed[default_mask], 3, method_dict[method])[pad:-pad, pad:-pad, :]\n",
    "\n",
    "    return frames_inpainted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% (198 of 242) |##################    | Elapsed Time: 0:08:57 ETA:   0:01:46"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing mask files: ['data/mask/199_paper_covid_prc_convex_frame0_mask.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82% (199 of 242) |##################    | Elapsed Time: 0:08:58 ETA:   0:00:47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing mask files: ['data/mask/200_paper_covid_prc_convex_frame0_mask.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (242 of 242) |######################| Elapsed Time: 0:13:47 Time:  0:13:47\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# ... other necessary imports ...\n",
    "\n",
    "CLEAN_IMAGE_OUT = 'data/image/clean/'\n",
    "CLEAN_VIDEO_OUT = 'data/video/clean/'\n",
    "\n",
    "# create clean image and video folders if they don't already exist\n",
    "if not os.path.exists(CLEAN_IMAGE_OUT):\n",
    "    os.makedirs(CLEAN_IMAGE_OUT)\n",
    "if not os.path.exists(CLEAN_VIDEO_OUT):\n",
    "    os.makedirs(CLEAN_VIDEO_OUT)\n",
    "\n",
    "# ... other function definitions like zero_pad_array and frame_inpainting ...\n",
    "\n",
    "progress = ProgressBar(max_value=image_prc_df.shape[0])\n",
    "\n",
    "for idx, row in progress(image_prc_df.iterrows()):\n",
    "    if row.probe == 'Convex':\n",
    "        filename_main = row.filename.split('.')[0] + '_prc_convex'\n",
    "    elif row.probe == 'Linear':\n",
    "        filename_main = row.filename.split('.')[0] + '_prc_linear'\n",
    "\n",
    "    if row.tight_inpainting == 'yes':\n",
    "        inpainting_kernel_size = (1,1)  # objects close to ROI, avoid bleeding while inpainting\n",
    "    else:\n",
    "        inpainting_kernel_size = (5,5)  # no objects close to ROI, more effective inpainting\n",
    "\n",
    "    if row.need_mask_after_crop == 'no':\n",
    "        frames = {}\n",
    "        for file in os.listdir(IMAGE_CROPPED_OUT):\n",
    "            if file.startswith(filename_main):\n",
    "                new_filename = file.replace('frame', 'clean_frame')\n",
    "                shutil.copy(os.path.join(IMAGE_CROPPED_OUT, file), os.path.join(CLEAN_IMAGE_OUT, new_filename))\n",
    "                img = cv2.imread(os.path.join(CLEAN_IMAGE_OUT, new_filename))\n",
    "                frame_num = int(re.search(r'\\d+$', file[:-4]).group())\n",
    "                frames[frame_num] = img\n",
    "\n",
    "        clean_vid_frames = [frames[k] for k in sorted(frames.keys())]\n",
    "        h, w, layers = clean_vid_frames[0].shape\n",
    "        out = cv2.VideoWriter(os.path.join(CLEAN_VIDEO_OUT, filename_main + '_clean.avi'), cv2.VideoWriter_fourcc(*'DIVX'), 15, (w, h))\n",
    "        for frame in clean_vid_frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "\n",
    "    else: \n",
    "        frames = {}\n",
    "        for f in os.listdir(IMAGE_CROPPED_OUT):\n",
    "            if f.startswith(filename_main):\n",
    "                img = cv2.imread(os.path.join(IMAGE_CROPPED_OUT, f))\n",
    "                frame_num = int(re.search(r'\\d+$', f[:-4]).group())\n",
    "                frames[frame_num] = img\n",
    "\n",
    "        masks = {}\n",
    "        missing_masks = []\n",
    "\n",
    "        if row.need_multiple_masks == 'no':\n",
    "            mask_file = os.path.join(IMAGE_MASK_OUT, filename_main + '_frame0_mask.jpg')\n",
    "            if os.path.exists(mask_file):\n",
    "                mask = cv2.imread(mask_file)[:,:,0]\n",
    "                frames_inpainted = frame_inpainting(frames, mask, kernel_size=inpainting_kernel_size)\n",
    "            else:\n",
    "                missing_masks.append(mask_file)\n",
    "\n",
    "        else:\n",
    "            for f in os.listdir(IMAGE_MASK_OUT):\n",
    "                if f.startswith(filename_main):\n",
    "                    mask_file = os.path.join(IMAGE_MASK_OUT, f)\n",
    "                    if os.path.exists(mask_file):\n",
    "                        img = cv2.imread(mask_file)\n",
    "                        frame_num = int(re.search(r'\\d+$', f[:-9]).group())\n",
    "                        masks[frame_num] = img[:,:,0]\n",
    "                    else:\n",
    "                        missing_masks.append(mask_file)\n",
    "\n",
    "            if masks:\n",
    "                frames_inpainted = frame_inpainting(frames, masks, default_mask=0, kernel_size=inpainting_kernel_size)\n",
    "\n",
    "        for key, value in frames_inpainted.items():\n",
    "            cv2.imwrite(os.path.join(CLEAN_IMAGE_OUT, filename_main + \"_clean_frame\" + str(key) + \".jpg\"), value)\n",
    "\n",
    "        clean_vid_frames = [frames_inpainted[k] for k in sorted(frames_inpainted.keys())]\n",
    "        h, w, layers = clean_vid_frames[0].shape\n",
    "        out = cv2.VideoWriter(os.path.join(CLEAN_VIDEO_OUT, filename_main + '_clean.avi'), cv2.VideoWriter_fourcc(*'DIVX'), 15, (w, h))\n",
    "        for frame in clean_vid_frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "\n",
    "        if missing_masks:\n",
    "            print(f\"Missing mask files: {missing_masks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
